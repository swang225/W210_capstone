{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "667853d8-316f-44b7-802c-f31c1a0e8574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import clip\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c96d6cf1-e21b-40e7-b46e-945ebc904f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(dir):\n",
    "    with open(dir, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    return b\n",
    "\n",
    "\n",
    "def write_pickle(dir, data):\n",
    "    with open(dir, 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b9fe7a4-4d27-4c4f-a6d2-c49504a06ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_path(uid):\n",
    "    return osp.join(image_storage, f\"{uid}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf5efcdd-3fd0-4c4b-b305-e6dfc52fb5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"C:/Users/aphri/Documents/t0002/work/data/w210_data/target_store_furniture_datasets.csv\"\n",
    "image_storage = \"C:/Users/aphri/Documents/t0002/work/data/w210_data/target_images\"\n",
    "pickle_path = \"C:/Users/aphri/Documents/t0002/work/data/w210_data/pickle\"\n",
    "model_path = \"C:/Users/aphri/Documents/t0002/work/data/w210_data/model\"\n",
    "\n",
    "Path(image_storage).mkdir(parents=True, exist_ok=True)\n",
    "Path(pickle_path).mkdir(parents=True, exist_ok=True)\n",
    "Path(model_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d03c8438-a448-4d70-81a9-d0baefde2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = osp.join(pickle_path, \"1000.pkl\")\n",
    "data = read_pickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "567c4573-8c93-4376-b598-356653f0281f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>text</th>\n",
       "      <th>encoded_image</th>\n",
       "      <th>encoded_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c456e14d-0693-5552-8f90-eead4a0f1f50</td>\n",
       "      <td>Desks</td>\n",
       "      <td>[[[tensor([1.9303, 1.9303, 1.9303, 1.9303, 1.9...</td>\n",
       "      <td>[[tensor(49406, dtype=torch.int32), tensor(410...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b020d91e-77ab-5c3e-b1e6-2fe01abe41b6</td>\n",
       "      <td>Dressers</td>\n",
       "      <td>[[[tensor([1.9303, 1.9303, 1.9303, 1.9303, 1.9...</td>\n",
       "      <td>[[tensor(49406, dtype=torch.int32), tensor(126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d0972ad8-c10a-5d84-86a1-4d25cd361229</td>\n",
       "      <td>Beds</td>\n",
       "      <td>[[[tensor([1.9303, 1.9303, 1.9303, 1.9303, 1.9...</td>\n",
       "      <td>[[tensor(49406, dtype=torch.int32), tensor(139...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dade134d-f251-5120-97be-23eb1e01c0f8</td>\n",
       "      <td>Storage Furniture</td>\n",
       "      <td>[[[tensor([1.9303, 1.9303, 1.9303, 1.9303, 1.9...</td>\n",
       "      <td>[[tensor(49406, dtype=torch.int32), tensor(682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f2e0d558-e93f-541b-98b1-6fff36f1dc89</td>\n",
       "      <td>Patio Chairs</td>\n",
       "      <td>[[[tensor([1.9303, 1.9303, 1.9303, 1.9303, 1.9...</td>\n",
       "      <td>[[tensor(49406, dtype=torch.int32), tensor(143...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    uid               text  \\\n",
       "0  c456e14d-0693-5552-8f90-eead4a0f1f50              Desks   \n",
       "1  b020d91e-77ab-5c3e-b1e6-2fe01abe41b6           Dressers   \n",
       "2  d0972ad8-c10a-5d84-86a1-4d25cd361229               Beds   \n",
       "3  dade134d-f251-5120-97be-23eb1e01c0f8  Storage Furniture   \n",
       "4  f2e0d558-e93f-541b-98b1-6fff36f1dc89       Patio Chairs   \n",
       "\n",
       "                                       encoded_image  \\\n",
       "0  [[[tensor([1.9303, 1.9303, 1.9303, 1.9303, 1.9...   \n",
       "1  [[[tensor([1.9303, 1.9303, 1.9303, 1.9303, 1.9...   \n",
       "2  [[[tensor([1.9303, 1.9303, 1.9303, 1.9303, 1.9...   \n",
       "3  [[[tensor([1.9303, 1.9303, 1.9303, 1.9303, 1.9...   \n",
       "4  [[[tensor([1.9303, 1.9303, 1.9303, 1.9303, 1.9...   \n",
       "\n",
       "                                        encoded_text  \n",
       "0  [[tensor(49406, dtype=torch.int32), tensor(410...  \n",
       "1  [[tensor(49406, dtype=torch.int32), tensor(126...  \n",
       "2  [[tensor(49406, dtype=torch.int32), tensor(139...  \n",
       "3  [[tensor(49406, dtype=torch.int32), tensor(682...  \n",
       "4  [[tensor(49406, dtype=torch.int32), tensor(143...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7d911f8-b1b4-47f6-9d16-3aae1ea989a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"demo_data/image\"\n",
    "\n",
    "for uid in data[\"uid\"]:\n",
    "    new_path = osp.join(base, f\"{uid}.jpg\")\n",
    "    shutil.copyfile(image_path(uid), new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fe1fad-7ea2-447b-9cba-7012a7b88095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
