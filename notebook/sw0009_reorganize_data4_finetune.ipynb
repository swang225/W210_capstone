{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be2c837-894e-4db1-9e57-dde850034a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aphri\\miniconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] The specified procedure could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import clip\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "401aad3c-ffe6-40f4-be07-bc9ec672311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(dir):\n",
    "    with open(dir, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    return b\n",
    "\n",
    "\n",
    "def write_pickle(dir, data):\n",
    "    with open(dir, 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e48e4f-10e0-4d0f-92ae-aaa47bd944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_path(uid):\n",
    "    return osp.join(image_storage, f\"{uid}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a943d4f-7166-4b92-b81e-ae7effbb4ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_category(x):\n",
    "    res = x[\"sub_category_1\"]\n",
    "    if not pd.isna(x[\"sub_category_2\"]):\n",
    "        res += \", \" + x[\"sub_category_2\"]\n",
    "    if not pd.isna(x[\"sub_category_3\"]):\n",
    "        res += \", \" + x[\"sub_category_3\"]\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def clean_data(d1):\n",
    "    d1 = d1[d1[\"primary_category\"] == \"Furniture\"]\n",
    "    d1 = d1[~(d1[\"primary_category\"].isna() & d1[\"sub_category_1\"].isna() & d1[\"sub_category_2\"].isna() & d1[\"sub_category_3\"].isna())]\n",
    "    d1 = d1[~(d1[\"sub_category_1\"].isna() & d1[\"sub_category_2\"].isna() & d1[\"sub_category_3\"].isna())]\n",
    "    d1 = d1[~d1[\"description\"].isna()]\n",
    "    d1 = d1[~d1[\"colors\"].isna()]\n",
    "    d1[\"colors\"] = d1[\"colors\"].astype(str)\n",
    "    d1[\"combined_category\"] = d1.apply(combine_category, axis=1)\n",
    "    return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b531ba2b-1882-4d86-b513-6dd000b2e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_title(x):\n",
    "    res = x[\"title\"]\n",
    "    if not pd.isna(x[\"colors\"]):\n",
    "        res += \", \" + x[\"colors\"]\n",
    "    if not pd.isna(x[\"material\"]):\n",
    "        res += \", \" + x[\"material\"]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bce7809c-98a0-4bae-a4e6-001173ab401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/cleaned_target_furniture_dataset.csv\"\n",
    "pickle_path = \"C:/Users/aphri/Documents/t0002/work/data/w210_data/data_finetuned_pickle\"\n",
    "image_pickle_path = \"C:/Users/aphri/Documents/t0002/work/data/w210_data/data_finetuned_image_pickle\"\n",
    "model_path = \"C:/Users/aphri/Documents/t0002/work/data/w210_data/finetuned_model/finetuned_model.pt\"\n",
    "image_storage = \"C:/Users/aphri/Documents/t0002/work/data/w210_data/target_images\"\n",
    "\n",
    "Path(pickle_path).mkdir(parents=True, exist_ok=True)\n",
    "Path(image_pickle_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5f9fd02-42e6-4d27-ae40-8777bb45196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cc60eff-7441-4b3c-a417-f97578ec5893",
   "metadata": {},
   "outputs": [],
   "source": [
    "if osp.exists(model_path):\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    # optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bd526d2-ea7f-4a6f-ba37-b28d04cd1239",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv(dataset_path)\n",
    "d1 = clean_data(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6a0f3b6-ae5c-4988-b95e-1e1e86b36c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = d1[d1[\"combined_category\"] == \"Home Office Furniture, Bookshelves & Bookcases\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "740d6466-0c4e-4f10-9ff1-0705fd0e40db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1103"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab51a234-45ad-4c36-9d14-3d33726e7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1[\"combined_title\"] = d1.apply(combine_title, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "769b9405-6de0-433e-95c8-447dfeaba854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best Choice Products 9-Cube Bookshelf, Display Storage System, Compartment Organizer w/ 3 Removable Back Panels - Black, black, MDF (Medium-Density Fiberboard) '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1[\"combined_title\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4362cdf6-511f-4493-a13b-6ebc819c9798",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = d1[[\"uniq_id\", \"combined_category\", \"combined_title\"]]\n",
    "d2.columns = [\"uniq_id\", \"combined_category\", \"title\"]\n",
    "write_pickle(osp.join(pickle_path, f\"meta_data.pkl\"), d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bbe2210-c634-4045-b089-4444a585b5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving encoded categories\n"
     ]
    }
   ],
   "source": [
    "cat_set = set(d1[\"combined_category\"].values)\n",
    "\n",
    "cat_list = []\n",
    "ecat_list = []\n",
    "\n",
    "for cat in cat_set:\n",
    "    \n",
    "    ecat = clip.tokenize(cat)\n",
    "    cat_list.append(cat)\n",
    "    ecat_list.append(ecat)\n",
    "    \n",
    "ecat_list = torch.cat(ecat_list).to(device)\n",
    "with torch.no_grad():\n",
    "    ecat_list = list(model.encode_text(ecat_list))\n",
    "\n",
    "print(f\"saving encoded categories\")\n",
    "df = pd.DataFrame(data={\n",
    "    \"category\": cat_list,\n",
    "    \"encoded_category\": ecat_list\n",
    "})\n",
    "\n",
    "write_pickle(osp.join(pickle_path, f\"categories.pkl\"), df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1f0f1f0-509e-4987-a4ac-1c8009c52213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\n",
      "45.5%\n",
      "90.99%\n",
      "136.49%\n",
      "saving encoded titles\n"
     ]
    }
   ],
   "source": [
    "title_set = set(d1[\"combined_title\"].values)\n",
    "\n",
    "title_list = []\n",
    "etitle_list = []\n",
    "\n",
    "for title in title_set:\n",
    "    \n",
    "    etitle = clip.tokenize(title)\n",
    "    title_list.append(title)\n",
    "    etitle_list.append(etitle)\n",
    "    \n",
    "res = []\n",
    "chunk = 500\n",
    "idx = 0\n",
    "total_len = len(etitle_list)\n",
    "while True:\n",
    "    print(f\"{round(idx*100/total_len, 2)}%\")\n",
    "    if idx >= len(etitle_list):\n",
    "        break\n",
    "    curr_list = torch.cat(etitle_list[idx:idx+chunk]).to(device)\n",
    "    with torch.no_grad():\n",
    "        curr_list = list(model.encode_text(curr_list))\n",
    "        res += curr_list\n",
    "    idx += chunk\n",
    "\n",
    "print(f\"saving encoded titles\")\n",
    "df = pd.DataFrame(data={\n",
    "    \"title\": title_list,\n",
    "    \"encoded_title\": res\n",
    "})\n",
    "\n",
    "write_pickle(osp.join(pickle_path, f\"titles.pkl\"), df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbc01efb-00c6-4119-bd1e-5311f5008ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\n"
     ]
    }
   ],
   "source": [
    "total_len = len(cat_set)\n",
    "cidx = 0\n",
    "printed_cidx = set()\n",
    "for cat in cat_set:\n",
    "    \n",
    "    pct = int(round(cidx*100/total_len, 0))\n",
    "    if pct % 10 == 0 and pct not in printed_cidx:\n",
    "        print(f\"{pct}%\")\n",
    "        printed_cidx.add(pct)\n",
    "    \n",
    "    cidx += 1\n",
    "    \n",
    "    store_path = osp.join(image_pickle_path, f\"{cat}.pkl\")\n",
    "    if osp.exists(store_path):\n",
    "        continue\n",
    "\n",
    "    uid_list = []\n",
    "    for idx, row in d1[d1[\"combined_category\"] == cat].iterrows():\n",
    "        uid = row.uniq_id\n",
    "        uid_list.append(uid)\n",
    "\n",
    "    image = torch.cat([preprocess(Image.open(image_path(uid))).unsqueeze(0) for uid in uid_list]).to(device)\n",
    "    with torch.no_grad():\n",
    "        eimage_list = list(model.encode_image(image))\n",
    "        \n",
    "    if len(uid_list) > 0:\n",
    "        df = pd.DataFrame(data={\n",
    "            \"uid\": uid_list,\n",
    "            \"encoded_image\": eimage_list\n",
    "        })\n",
    "        write_pickle(store_path, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef5f6bc-ec09-4689-9a56-831149856a36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
